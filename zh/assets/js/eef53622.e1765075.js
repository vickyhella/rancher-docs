"use strict";(self.webpackChunkrancher_docs=self.webpackChunkrancher_docs||[]).push([[22675],{3905:function(e,n,t){t.d(n,{Zo:function(){return u},kt:function(){return m}});var r=t(67294);function a(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function i(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);n&&(r=r.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,r)}return t}function o(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?i(Object(t),!0).forEach((function(n){a(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):i(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function s(e,n){if(null==e)return{};var t,r,a=function(e,n){if(null==e)return{};var t,r,a={},i=Object.keys(e);for(r=0;r<i.length;r++)t=i[r],n.indexOf(t)>=0||(a[t]=e[t]);return a}(e,n);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(r=0;r<i.length;r++)t=i[r],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(a[t]=e[t])}return a}var c=r.createContext({}),l=function(e){var n=r.useContext(c),t=n;return e&&(t="function"==typeof e?e(n):o(o({},n),e)),t},u=function(e){var n=l(e.components);return r.createElement(c.Provider,{value:n},e.children)},d={inlineCode:"code",wrapper:function(e){var n=e.children;return r.createElement(r.Fragment,{},n)}},p=r.forwardRef((function(e,n){var t=e.components,a=e.mdxType,i=e.originalType,c=e.parentName,u=s(e,["components","mdxType","originalType","parentName"]),p=l(t),m=a,h=p["".concat(c,".").concat(m)]||p[m]||d[m]||i;return t?r.createElement(h,o(o({ref:n},u),{},{components:t})):r.createElement(h,o({ref:n},u))}));function m(e,n){var t=arguments,a=n&&n.mdxType;if("string"==typeof e||a){var i=t.length,o=new Array(i);o[0]=p;var s={};for(var c in n)hasOwnProperty.call(n,c)&&(s[c]=n[c]);s.originalType=e,s.mdxType="string"==typeof e?e:a,o[1]=s;for(var l=2;l<i;l++)o[l]=t[l];return r.createElement.apply(null,o)}return r.createElement.apply(null,t)}p.displayName="MDXCreateElement"},33697:function(e,n,t){t.r(n),t.d(n,{assets:function(){return u},contentTitle:function(){return c},default:function(){return m},frontMatter:function(){return s},metadata:function(){return l},toc:function(){return d}});var r=t(87462),a=t(63366),i=(t(67294),t(3905)),o=["components"],s={title:"Hardening Guide v2.3.5"},c=void 0,l={unversionedId:"reference-guides/rancher-security/rancher-v2.3-hardening-guides/rancher-v2.3.5-hardening-guide-with-cis-v1.5-benchmark",id:"version-2.0-2.4/reference-guides/rancher-security/rancher-v2.3-hardening-guides/rancher-v2.3.5-hardening-guide-with-cis-v1.5-benchmark",title:"Hardening Guide v2.3.5",description:"This document provides prescriptive guidance for hardening a production installation of Rancher v2.3.5. It outlines the configurations and controls required to address Kubernetes benchmark controls from the Center for Information Security (CIS).",source:"@site/versioned_docs/version-2.0-2.4/reference-guides/rancher-security/rancher-v2.3-hardening-guides/rancher-v2.3.5-hardening-guide-with-cis-v1.5-benchmark.md",sourceDirName:"reference-guides/rancher-security/rancher-v2.3-hardening-guides",slug:"/reference-guides/rancher-security/rancher-v2.3-hardening-guides/rancher-v2.3.5-hardening-guide-with-cis-v1.5-benchmark",permalink:"/zh/v2.0-v2.4/reference-guides/rancher-security/rancher-v2.3-hardening-guides/rancher-v2.3.5-hardening-guide-with-cis-v1.5-benchmark",draft:!1,editUrl:"https://github.com/rancher/rancher-docs/edit/main/versioned_docs/version-2.0-2.4/reference-guides/rancher-security/rancher-v2.3-hardening-guides/rancher-v2.3.5-hardening-guide-with-cis-v1.5-benchmark.md",tags:[],version:"2.0-2.4",lastUpdatedAt:1663953084,formattedLastUpdatedAt:"2022/9/23",frontMatter:{title:"Hardening Guide v2.3.5"},sidebar:"tutorialSidebar",previous:{title:"CIS Benchmark Rancher Self-Assessment Guide - v2.3.5",permalink:"/zh/v2.0-v2.4/reference-guides/rancher-security/rancher-v2.3-hardening-guides/rancher-v2.3.5-self-assessment-guide-with-cis-v1.5-benchmark"},next:{title:"Rancher v2.4",permalink:"/zh/v2.0-v2.4/pages-for-subheaders/rancher-v2.4-hardening-guides"}},u={},d=[{value:"Overview",id:"overview",level:3},{value:"Known Issues",id:"known-issues",level:4},{value:"Configure Kernel Runtime Parameters",id:"configure-kernel-runtime-parameters",level:3},{value:"Configure <code>etcd</code> user and group",id:"configure-etcd-user-and-group",level:3},{value:"create <code>etcd</code> user and group",id:"create-etcd-user-and-group",level:4},{value:"Set <code>automountServiceAccountToken</code> to <code>false</code> for <code>default</code> service accounts",id:"set-automountserviceaccounttoken-to-false-for-default-service-accounts",level:4},{value:"Ensure that all Namespaces have Network Policies defined",id:"ensure-that-all-namespaces-have-network-policies-defined",level:3},{value:"Reference Hardened RKE <code>cluster.yml</code> configuration",id:"reference-hardened-rke-clusteryml-configuration",level:3},{value:"Reference Hardened RKE Template configuration",id:"reference-hardened-rke-template-configuration",level:3},{value:"Hardened Reference Ubuntu 18.04 LTS <strong>cloud-config</strong>:",id:"hardened-reference-ubuntu-1804-lts-cloud-config",level:3}],p={toc:d};function m(e){var n=e.components,t=(0,a.Z)(e,o);return(0,i.kt)("wrapper",(0,r.Z)({},p,t,{components:n,mdxType:"MDXLayout"}),(0,i.kt)("p",null,"This document provides prescriptive guidance for hardening a production installation of Rancher v2.3.5. It outlines the configurations and controls required to address Kubernetes benchmark controls from the Center for Information Security (CIS)."),(0,i.kt)("blockquote",null,(0,i.kt)("p",{parentName:"blockquote"},"This hardening guide describes how to secure the nodes in your cluster, and it is recommended to follow this guide before installing Kubernetes.")),(0,i.kt)("p",null,"This hardening guide is intended to be used with specific versions of the CIS Kubernetes Benchmark, Kubernetes, and Rancher:"),(0,i.kt)("table",null,(0,i.kt)("thead",{parentName:"table"},(0,i.kt)("tr",{parentName:"thead"},(0,i.kt)("th",{parentName:"tr",align:null},"Hardening Guide Version"),(0,i.kt)("th",{parentName:"tr",align:null},"Rancher Version"),(0,i.kt)("th",{parentName:"tr",align:null},"CIS Benchmark Version"),(0,i.kt)("th",{parentName:"tr",align:null},"Kubernetes Version"))),(0,i.kt)("tbody",{parentName:"table"},(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"Hardening Guide v2.3.5"),(0,i.kt)("td",{parentName:"tr",align:null},"Rancher v2.3.5"),(0,i.kt)("td",{parentName:"tr",align:null},"Benchmark v1.5"),(0,i.kt)("td",{parentName:"tr",align:null},"Kubernetes 1.15")))),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://releases.rancher.com/documents/security/2.3.5/Rancher_Hardening_Guide.pdf"},"Click here to download a PDF version of this document")),(0,i.kt)("h3",{id:"overview"},"Overview"),(0,i.kt)("p",null,"This document provides prescriptive guidance for hardening a production installation of Rancher v2.3.5 with Kubernetes v1.15. It outlines the configurations required to address Kubernetes benchmark controls from the Center for Information Security (CIS)."),(0,i.kt)("p",null,"For more detail about evaluating a hardened cluster against the official CIS benchmark, refer to the ",(0,i.kt)("a",{parentName:"p",href:"/zh/v2.0-v2.4/reference-guides/rancher-security/rancher-v2.3-hardening-guides/rancher-v2.3.5-self-assessment-guide-with-cis-v1.5-benchmark"},"CIS Benchmark Rancher Self-Assessment Guide - Rancher v2.3.5"),"."),(0,i.kt)("h4",{id:"known-issues"},"Known Issues"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Rancher ",(0,i.kt)("strong",{parentName:"li"},"exec shell")," and ",(0,i.kt)("strong",{parentName:"li"},"view logs")," for pods are ",(0,i.kt)("strong",{parentName:"li"},"not")," functional in a CIS 1.5 hardened setup when only public IP is provided when registering custom nodes. This functionality requires a private IP to be provided when registering the custom nodes."),(0,i.kt)("li",{parentName:"ul"},"When setting the ",(0,i.kt)("inlineCode",{parentName:"li"},"default_pod_security_policy_template_id:")," to ",(0,i.kt)("inlineCode",{parentName:"li"},"restricted")," Rancher creates ",(0,i.kt)("strong",{parentName:"li"},"RoleBindings")," and ",(0,i.kt)("strong",{parentName:"li"},"ClusterRoleBindings")," on the default service accounts. The CIS 1.5 5.1.5 check requires the default service accounts have no roles or cluster roles bound to it apart from the defaults. In addition the default service accounts should be configured such that it does not provide a service account token and does not have any explicit rights assignments.")),(0,i.kt)("h3",{id:"configure-kernel-runtime-parameters"},"Configure Kernel Runtime Parameters"),(0,i.kt)("p",null,"The following ",(0,i.kt)("inlineCode",{parentName:"p"},"sysctl")," configuration is recommended for all nodes type in the cluster. Set the following parameters in ",(0,i.kt)("inlineCode",{parentName:"p"},"/etc/sysctl.d/90-kubelet.conf"),":"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"vm.overcommit_memory=1\nvm.panic_on_oom=0\nkernel.panic=10\nkernel.panic_on_oops=1\nkernel.keys.root_maxbytes=25000000\n")),(0,i.kt)("p",null,"Run ",(0,i.kt)("inlineCode",{parentName:"p"},"sysctl -p /etc/sysctl.d/90-kubelet.conf")," to enable the settings."),(0,i.kt)("h3",{id:"configure-etcd-user-and-group"},"Configure ",(0,i.kt)("inlineCode",{parentName:"h3"},"etcd")," user and group"),(0,i.kt)("p",null,"A user account and group for the ",(0,i.kt)("strong",{parentName:"p"},"etcd")," service is required to be setup before installing RKE. The ",(0,i.kt)("strong",{parentName:"p"},"uid")," and ",(0,i.kt)("strong",{parentName:"p"},"gid")," for the ",(0,i.kt)("strong",{parentName:"p"},"etcd")," user will be used in the RKE ",(0,i.kt)("strong",{parentName:"p"},"config.yml")," to set the proper permissions for files and directories during installation time."),(0,i.kt)("h4",{id:"create-etcd-user-and-group"},"create ",(0,i.kt)("inlineCode",{parentName:"h4"},"etcd")," user and group"),(0,i.kt)("p",null,"To create the ",(0,i.kt)("strong",{parentName:"p"},"etcd")," group run the following console commands."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},'groupadd --gid 52034 etcd\nuseradd --comment "etcd service account" --uid 52034 --gid 52034 etcd\n')),(0,i.kt)("p",null,"Update the RKE ",(0,i.kt)("strong",{parentName:"p"},"config.yml")," with the ",(0,i.kt)("strong",{parentName:"p"},"uid")," and ",(0,i.kt)("strong",{parentName:"p"},"gid")," of the ",(0,i.kt)("strong",{parentName:"p"},"etcd")," user:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml"},"services:\n  etcd:\n    gid: 52034\n    uid: 52034\n")),(0,i.kt)("h4",{id:"set-automountserviceaccounttoken-to-false-for-default-service-accounts"},"Set ",(0,i.kt)("inlineCode",{parentName:"h4"},"automountServiceAccountToken")," to ",(0,i.kt)("inlineCode",{parentName:"h4"},"false")," for ",(0,i.kt)("inlineCode",{parentName:"h4"},"default")," service accounts"),(0,i.kt)("p",null,"Kubernetes provides a default service account which is used by cluster workloads where no specific service account is assigned to the pod. Where access to the Kubernetes API from a pod is required, a specific service account should be created for that pod, and rights granted to that service account. The default service account should be configured such that it does not provide a service account token and does not have any explicit rights assignments."),(0,i.kt)("p",null,"For each namespace the ",(0,i.kt)("strong",{parentName:"p"},"default")," service account must include this value:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"automountServiceAccountToken: false\n")),(0,i.kt)("p",null,"Save the following yaml to a file called ",(0,i.kt)("inlineCode",{parentName:"p"},"account_update.yaml")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: default\nautomountServiceAccountToken: false\n")),(0,i.kt)("p",null,"Create a bash script file called ",(0,i.kt)("inlineCode",{parentName:"p"},"account_update.sh"),". Be sure to ",(0,i.kt)("inlineCode",{parentName:"p"},"chmod +x account_update.sh")," so the script has execute permissions."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"#!/bin/bash -e\n\nfor namespace in $(kubectl get namespaces -A -o json | jq -r '.items[].metadata.name'); do\n  kubectl patch serviceaccount default -n ${namespace} -p \"$(cat account_update.yaml)\"\ndone\n")),(0,i.kt)("h3",{id:"ensure-that-all-namespaces-have-network-policies-defined"},"Ensure that all Namespaces have Network Policies defined"),(0,i.kt)("p",null,"Running different applications on the same Kubernetes cluster creates a risk of one\ncompromised application attacking a neighboring application. Network segmentation is\nimportant to ensure that containers can communicate only with those they are supposed\nto. A network policy is a specification of how selections of pods are allowed to\ncommunicate with each other and other network endpoints."),(0,i.kt)("p",null,"Network Policies are namespace scoped. When a network policy is introduced to a given\nnamespace, all traffic not allowed by the policy is denied. However, if there are no network\npolicies in a namespace all traffic will be allowed into and out of the pods in that\nnamespace. To enforce network policies, a CNI (container network interface) plugin must be enabled.\nThis guide uses ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/projectcalico/canal"},"canal")," to provide the policy enforcement.\nAdditional information about CNI providers can be found\n",(0,i.kt)("a",{parentName:"p",href:"https://rancher.com/blog/2019/2019-03-21-comparing-kubernetes-cni-providers-flannel-calico-canal-and-weave/"},"here")),(0,i.kt)("p",null,"Once a CNI provider is enabled on a cluster a default network policy can be applied. For reference purposes a\n",(0,i.kt)("strong",{parentName:"p"},"permissive")," example is provide below. If you want to allow all traffic to all pods in a namespace\n(even if policies are added that cause some pods to be treated as \u201cisolated\u201d),\nyou can create a policy that explicitly allows all traffic in that namespace. Save the following ",(0,i.kt)("inlineCode",{parentName:"p"},"yaml")," as\n",(0,i.kt)("inlineCode",{parentName:"p"},"default-allow-all.yaml"),". Additional ",(0,i.kt)("a",{parentName:"p",href:"https://kubernetes.io/docs/concepts/services-networking/network-policies/"},"documentation"),"\nabout network policies can be found on the Kubernetes site."),(0,i.kt)("blockquote",null,(0,i.kt)("p",{parentName:"blockquote"},"This ",(0,i.kt)("inlineCode",{parentName:"p"},"NetworkPolicy")," is not recommended for production use")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml"},"---\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: default-allow-all\nspec:\n  podSelector: {}\n  ingress:\n  - {}\n  egress:\n  - {}\n  policyTypes:\n  - Ingress\n  - Egress\n")),(0,i.kt)("p",null,"Create a bash script file called ",(0,i.kt)("inlineCode",{parentName:"p"},"apply_networkPolicy_to_all_ns.sh"),". Be sure to\n",(0,i.kt)("inlineCode",{parentName:"p"},"chmod +x apply_networkPolicy_to_all_ns.sh")," so the script has execute permissions."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"#!/bin/bash -e\n\nfor namespace in $(kubectl get namespaces -A -o json | jq -r '.items[].metadata.name'); do\n  kubectl apply -f default-allow-all.yaml -n ${namespace}\ndone\n")),(0,i.kt)("p",null,"Execute this script to apply the ",(0,i.kt)("inlineCode",{parentName:"p"},"default-allow-all.yaml")," the ",(0,i.kt)("strong",{parentName:"p"},"permissive")," ",(0,i.kt)("inlineCode",{parentName:"p"},"NetworkPolicy")," to all namespaces."),(0,i.kt)("h3",{id:"reference-hardened-rke-clusteryml-configuration"},"Reference Hardened RKE ",(0,i.kt)("inlineCode",{parentName:"h3"},"cluster.yml")," configuration"),(0,i.kt)("p",null,"The reference ",(0,i.kt)("inlineCode",{parentName:"p"},"cluster.yml")," is used by the RKE CLI that provides the configuration needed to achieve a hardened install\nof Rancher Kubernetes Engine (RKE). Install ",(0,i.kt)("a",{parentName:"p",href:"https://rancher.com/docs/rke/latest/en/installation/"},"documentation")," is\nprovided with additional details about the configuration items."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml"},'# If you intend to deploy Kubernetes in an air-gapped environment,\n# please consult the documentation on how to configure custom RKE images.\nkubernetes_version: "v1.15.9-rancher1-1"\nenable_network_policy: true\ndefault_pod_security_policy_template_id: "restricted"\nservices:\n  etcd:\n    uid: 52034\n    gid: 52034\n  kube-api:\n    pod_security_policy: true\n    secrets_encryption_config:\n      enabled: true\n    audit_log:\n      enabled: true\n    admission_configuration:\n    event_rate_limit:\n      enabled: true\n  kube-controller:\n    extra_args:\n      feature-gates: "RotateKubeletServerCertificate=true"\n  scheduler:\n    image: ""\n    extra_args: {}\n    extra_binds: []\n    extra_env: []\n  kubelet:\n    generate_serving_certificate: true\n    extra_args:\n      feature-gates: "RotateKubeletServerCertificate=true"\n      protect-kernel-defaults: "true"\n      tls-cipher-suites: "TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_128_GCM_SHA256"\n    extra_binds: []\n    extra_env: []\n    cluster_domain: ""\n    infra_container_image: ""\n    cluster_dns_server: ""\n    fail_swap_on: false\n  kubeproxy:\n    image: ""\n    extra_args: {}\n    extra_binds: []\n    extra_env: []\nnetwork:\n  plugin: ""\n  options: {}\n  mtu: 0\n  node_selector: {}\nauthentication:\n  strategy: ""\n  sans: []\n  webhook: null\naddons: |\n  ---\n  apiVersion: v1\n  kind: Namespace\n  metadata:\n    name: ingress-nginx\n  ---\n  apiVersion: rbac.authorization.k8s.io/v1\n  kind: Role\n  metadata:\n    name: default-psp-role\n    namespace: ingress-nginx\n  rules:\n  - apiGroups:\n    - extensions\n    resourceNames:\n    - default-psp\n    resources:\n    - podsecuritypolicies\n    verbs:\n    - use\n  ---\n  apiVersion: rbac.authorization.k8s.io/v1\n  kind: RoleBinding\n  metadata:\n    name: default-psp-rolebinding\n    namespace: ingress-nginx\n  roleRef:\n    apiGroup: rbac.authorization.k8s.io\n    kind: Role\n    name: default-psp-role\n  subjects:\n  - apiGroup: rbac.authorization.k8s.io\n    kind: Group\n    name: system:serviceaccounts\n  - apiGroup: rbac.authorization.k8s.io\n    kind: Group\n    name: system:authenticated\n  ---\n  apiVersion: v1\n  kind: Namespace\n  metadata:\n    name: cattle-system\n  ---\n  apiVersion: rbac.authorization.k8s.io/v1\n  kind: Role\n  metadata:\n    name: default-psp-role\n    namespace: cattle-system\n  rules:\n  - apiGroups:\n    - extensions\n    resourceNames:\n    - default-psp\n    resources:\n    - podsecuritypolicies\n    verbs:\n    - use\n  ---\n  apiVersion: rbac.authorization.k8s.io/v1\n  kind: RoleBinding\n  metadata:\n    name: default-psp-rolebinding\n    namespace: cattle-system\n  roleRef:\n    apiGroup: rbac.authorization.k8s.io\n    kind: Role\n    name: default-psp-role\n  subjects:\n  - apiGroup: rbac.authorization.k8s.io\n    kind: Group\n    name: system:serviceaccounts\n  - apiGroup: rbac.authorization.k8s.io\n    kind: Group\n    name: system:authenticated\n  ---\n  apiVersion: policy/v1beta1\n  kind: PodSecurityPolicy\n  metadata:\n    name: restricted\n  spec:\n    requiredDropCapabilities:\n    - NET_RAW\n    privileged: false\n    allowPrivilegeEscalation: false\n    defaultAllowPrivilegeEscalation: false\n    fsGroup:\n      rule: RunAsAny\n    runAsUser:\n      rule: MustRunAsNonRoot\n    seLinux:\n      rule: RunAsAny\n    supplementalGroups:\n      rule: RunAsAny\n    volumes:\n    - emptyDir\n    - secret\n    - persistentVolumeClaim\n    - downwardAPI\n    - configMap\n    - projected\n  ---\n  apiVersion: rbac.authorization.k8s.io/v1\n  kind: ClusterRole\n  metadata:\n    name: psp:restricted\n  rules:\n  - apiGroups:\n    - extensions\n    resourceNames:\n    - restricted\n    resources:\n    - podsecuritypolicies\n    verbs:\n    - use\n  ---\n  apiVersion: rbac.authorization.k8s.io/v1\n  kind: ClusterRoleBinding\n  metadata:\n    name: psp:restricted\n  roleRef:\n    apiGroup: rbac.authorization.k8s.io\n    kind: ClusterRole\n    name: psp:restricted\n  subjects:\n  - apiGroup: rbac.authorization.k8s.io\n    kind: Group\n    name: system:serviceaccounts\n  - apiGroup: rbac.authorization.k8s.io\n    kind: Group\n    name: system:authenticated\n  ---\n  apiVersion: v1\n  kind: ServiceAccount\n  metadata:\n    name: tiller\n    namespace: kube-system\n  ---\n  apiVersion: rbac.authorization.k8s.io/v1\n  kind: ClusterRoleBinding\n  metadata:\n    name: tiller\n  roleRef:\n    apiGroup: rbac.authorization.k8s.io\n    kind: ClusterRole\n    name: cluster-admin\n  subjects:\n  - kind: ServiceAccount\n    name: tiller\n    namespace: kube-system\n\naddons_include: []\nsystem_images:\n  etcd: ""\n  alpine: ""\n  nginx_proxy: ""\n  cert_downloader: ""\n  kubernetes_services_sidecar: ""\n  kubedns: ""\n  dnsmasq: ""\n  kubedns_sidecar: ""\n  kubedns_autoscaler: ""\n  coredns: ""\n  coredns_autoscaler: ""\n  kubernetes: ""\n  flannel: ""\n  flannel_cni: ""\n  calico_node: ""\n  calico_cni: ""\n  calico_controllers: ""\n  calico_ctl: ""\n  calico_flexvol: ""\n  canal_node: ""\n  canal_cni: ""\n  canal_flannel: ""\n  canal_flexvol: ""\n  weave_node: ""\n  weave_cni: ""\n  pod_infra_container: ""\n  ingress: ""\n  ingress_backend: ""\n  metrics_server: ""\n  windows_pod_infra_container: ""\nssh_key_path: ""\nssh_cert_path: ""\nssh_agent_auth: false\nauthorization:\n  mode: ""\n  options: {}\nignore_docker_version: false\nprivate_registries: []\ningress:\n  provider: ""\n  options: {}\n  node_selector: {}\n  extra_args: {}\n  dns_policy: ""\n  extra_envs: []\n  extra_volumes: []\n  extra_volume_mounts: []\ncluster_name: ""\nprefix_path: ""\naddon_job_timeout: 0\nbastion_host:\n  address: ""\n  port: ""\n  user: ""\n  ssh_key: ""\n  ssh_key_path: ""\n  ssh_cert: ""\n  ssh_cert_path: ""\nmonitoring:\n  provider: ""\n  options: {}\n  node_selector: {}\nrestore:\n  restore: false\n  snapshot_name: ""\ndns: null\n')),(0,i.kt)("h3",{id:"reference-hardened-rke-template-configuration"},"Reference Hardened RKE Template configuration"),(0,i.kt)("p",null,"The reference RKE Template provides the configuration needed to achieve a hardened install of Kubenetes.\nRKE Templates are used to provision Kubernetes and define Rancher settings. Follow the Rancher\n",(0,i.kt)("a",{parentName:"p",href:"https://rancher.com/docs/rancher/v2.0-v2.4/en/installation"},"documentaion")," for additional installation and RKE Template details."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml"},"#\n# Cluster Config\n#\ndefault_pod_security_policy_template_id: restricted\ndocker_root_dir: /var/lib/docker\nenable_cluster_alerting: false\nenable_cluster_monitoring: false\nenable_network_policy: true\n#\n# Rancher Config\n#\nrancher_kubernetes_engine_config:\n  addon_job_timeout: 30\n  addons: |-\n    ---\n    apiVersion: v1\n    kind: Namespace\n    metadata:\n      name: ingress-nginx\n    ---\n    apiVersion: rbac.authorization.k8s.io/v1\n    kind: Role\n    metadata:\n      name: default-psp-role\n      namespace: ingress-nginx\n    rules:\n    - apiGroups:\n      - extensions\n      resourceNames:\n      - default-psp\n      resources:\n      - podsecuritypolicies\n      verbs:\n      - use\n    ---\n    apiVersion: rbac.authorization.k8s.io/v1\n    kind: RoleBinding\n    metadata:\n      name: default-psp-rolebinding\n      namespace: ingress-nginx\n    roleRef:\n      apiGroup: rbac.authorization.k8s.io\n      kind: Role\n      name: default-psp-role\n    subjects:\n    - apiGroup: rbac.authorization.k8s.io\n      kind: Group\n      name: system:serviceaccounts\n    - apiGroup: rbac.authorization.k8s.io\n      kind: Group\n      name: system:authenticated\n    ---\n    apiVersion: v1\n    kind: Namespace\n    metadata:\n      name: cattle-system\n    ---\n    apiVersion: rbac.authorization.k8s.io/v1\n    kind: Role\n    metadata:\n      name: default-psp-role\n      namespace: cattle-system\n    rules:\n    - apiGroups:\n      - extensions\n      resourceNames:\n      - default-psp\n      resources:\n      - podsecuritypolicies\n      verbs:\n      - use\n    ---\n    apiVersion: rbac.authorization.k8s.io/v1\n    kind: RoleBinding\n    metadata:\n      name: default-psp-rolebinding\n      namespace: cattle-system\n    roleRef:\n      apiGroup: rbac.authorization.k8s.io\n      kind: Role\n      name: default-psp-role\n    subjects:\n    - apiGroup: rbac.authorization.k8s.io\n      kind: Group\n      name: system:serviceaccounts\n    - apiGroup: rbac.authorization.k8s.io\n      kind: Group\n      name: system:authenticated\n    ---\n    apiVersion: policy/v1beta1\n    kind: PodSecurityPolicy\n    metadata:\n      name: restricted\n    spec:\n      requiredDropCapabilities:\n      - NET_RAW\n      privileged: false\n      allowPrivilegeEscalation: false\n      defaultAllowPrivilegeEscalation: false\n      fsGroup:\n        rule: RunAsAny\n      runAsUser:\n        rule: MustRunAsNonRoot\n      seLinux:\n        rule: RunAsAny\n      supplementalGroups:\n        rule: RunAsAny\n      volumes:\n      - emptyDir\n      - secret\n      - persistentVolumeClaim\n      - downwardAPI\n      - configMap\n      - projected\n    ---\n    apiVersion: rbac.authorization.k8s.io/v1\n    kind: ClusterRole\n    metadata:\n      name: psp:restricted\n    rules:\n    - apiGroups:\n      - extensions\n      resourceNames:\n      - restricted\n      resources:\n      - podsecuritypolicies\n      verbs:\n      - use\n    ---\n    apiVersion: rbac.authorization.k8s.io/v1\n    kind: ClusterRoleBinding\n    metadata:\n      name: psp:restricted\n    roleRef:\n      apiGroup: rbac.authorization.k8s.io\n      kind: ClusterRole\n      name: psp:restricted\n    subjects:\n    - apiGroup: rbac.authorization.k8s.io\n      kind: Group\n      name: system:serviceaccounts\n    - apiGroup: rbac.authorization.k8s.io\n      kind: Group\n      name: system:authenticated\n    ---\n    apiVersion: v1\n    kind: ServiceAccount\n    metadata:\n      name: tiller\n      namespace: kube-system\n    ---\n    apiVersion: rbac.authorization.k8s.io/v1\n    kind: ClusterRoleBinding\n    metadata:\n      name: tiller\n    roleRef:\n      apiGroup: rbac.authorization.k8s.io\n      kind: ClusterRole\n      name: cluster-admin\n    subjects:\n    - kind: ServiceAccount\n      name: tiller\n      namespace: kube-system\n  ignore_docker_version: true\n  kubernetes_version: v1.15.9-rancher1-1\n#\n#   If you are using calico on AWS\n#\n#    network:\n#      plugin: calico\n#      calico_network_provider:\n#        cloud_provider: aws\n#\n# # To specify flannel interface\n#\n#    network:\n#      plugin: flannel\n#      flannel_network_provider:\n#      iface: eth1\n#\n# # To specify flannel interface for canal plugin\n#\n#    network:\n#      plugin: canal\n#      canal_network_provider:\n#        iface: eth1\n#\n  network:\n    mtu: 0\n    plugin: canal\n#\n#    services:\n#      kube-api:\n#        service_cluster_ip_range: 10.43.0.0/16\n#      kube-controller:\n#        cluster_cidr: 10.42.0.0/16\n#        service_cluster_ip_range: 10.43.0.0/16\n#      kubelet:\n#        cluster_domain: cluster.local\n#        cluster_dns_server: 10.43.0.10\n#\n  services:\n    etcd:\n      backup_config:\n        enabled: false\n        interval_hours: 12\n        retention: 6\n        safe_timestamp: false\n      creation: 12h\n      extra_args:\n        election-timeout: '5000'\n        heartbeat-interval: '500'\n      gid: 52034\n      retention: 72h\n      snapshot: false\n      uid: 52034\n    kube_api:\n      always_pull_images: false\n      audit_log:\n        enabled: true\n      event_rate_limit:\n        enabled: true\n      pod_security_policy: true\n      secrets_encryption_config:\n        enabled: true\n      service_node_port_range: 30000-32767\n    kube_controller:\n      extra_args:\n        address: 127.0.0.1\n        feature-gates: RotateKubeletServerCertificate=true\n        profiling: 'false'\n        terminated-pod-gc-threshold: '1000'\n    kubelet:\n      extra_args:\n        anonymous-auth: 'false'\n        event-qps: '0'\n        feature-gates: RotateKubeletServerCertificate=true\n        make-iptables-util-chains: 'true'\n        protect-kernel-defaults: 'true'\n        streaming-connection-idle-timeout: 1800s\n        tls-cipher-suites: >-\n          TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_128_GCM_SHA256\n      fail_swap_on: false\n      generate_serving_certificate: true\n    scheduler:\n      extra_args:\n        address: 127.0.0.1\n        profiling: 'false'\n  ssh_agent_auth: false\nwindows_prefered_cluster: false\n")),(0,i.kt)("h3",{id:"hardened-reference-ubuntu-1804-lts-cloud-config"},"Hardened Reference Ubuntu 18.04 LTS ",(0,i.kt)("strong",{parentName:"h3"},"cloud-config"),":"),(0,i.kt)("p",null,"The reference ",(0,i.kt)("strong",{parentName:"p"},"cloud-config")," is generally used in cloud infrastructure environments to allow for\nconfiguration management of compute instances. The reference config configures Ubuntu operating system level settings\nneeded before installing kubernetes."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml"},'#cloud-config\npackages:\n  - curl\n  - jq\nruncmd:\n  - sysctl -w vm.overcommit_memory=1\n  - sysctl -w kernel.panic=10\n  - sysctl -w kernel.panic_on_oops=1\n  - curl https://releases.rancher.com/install-docker/18.09.sh | sh\n  - usermod -aG docker ubuntu\n  - return=1; while [ $return != 0 ]; do sleep 2; docker ps; return=$?; done\n  - addgroup --gid 52034 etcd\n  - useradd --comment "etcd service account" --uid 52034 --gid 52034 etcd\nwrite_files:\n  - path: /etc/sysctl.d/kubelet.conf\n    owner: root:root\n    permissions: "0644"\n    content: |\n      vm.overcommit_memory=1\n      kernel.panic=10\n      kernel.panic_on_oops=1\n')))}m.isMDXComponent=!0}}]);